{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Image Classification Model\n",
    "\n",
    "This is a demo for training a model using the a subset of the imagenet dataset. This notebook is a version of https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_mnist.py where you can run the training via command line.\n",
    "\n",
    "We first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import find_mxnet\n",
    "import mxnet as mx\n",
    "import argparse\n",
    "import os, sys\n",
    "import train_model\n",
    "\n",
    "def _download(data_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.system(\"mkdir \" + data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    if (not os.path.exists('train-images-idx3-ubyte')) or \\\n",
    "       (not os.path.exists('train-labels-idx1-ubyte')) or \\\n",
    "       (not os.path.exists('t10k-images-idx3-ubyte')) or \\\n",
    "       (not os.path.exists('t10k-labels-idx1-ubyte')):\n",
    "        import urllib, zipfile\n",
    "        zippath = os.path.join(os.getcwd(), \"mnist.zip\")\n",
    "        urllib.urlretrieve(\"http://data.mxnet.io/mxnet/data/mnist.zip\", zippath)\n",
    "        zf = zipfile.ZipFile(zippath, \"r\")\n",
    "        zf.extractall()\n",
    "        zf.close()\n",
    "        os.remove(zippath)\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions are helper functions for when we want to use different types of networks. For this lab, we will be using mlp specifically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loc(data, attr={'lr_mult':'0.01'}):\n",
    "    \"\"\"\n",
    "    the localisation network in lenet-stn, it will increase acc about more than 1%,\n",
    "    when num-epoch >=15\n",
    "    \"\"\"\n",
    "    loc = mx.symbol.Convolution(data=data, num_filter=30, kernel=(5, 5), stride=(2,2))\n",
    "    loc = mx.symbol.Activation(data = loc, act_type='relu')\n",
    "    loc = mx.symbol.Pooling(data=loc, kernel=(2, 2), stride=(2, 2), pool_type='max')\n",
    "    loc = mx.symbol.Convolution(data=loc, num_filter=60, kernel=(3, 3), stride=(1,1), pad=(1, 1))\n",
    "    loc = mx.symbol.Activation(data = loc, act_type='relu')\n",
    "    loc = mx.symbol.Pooling(data=loc, global_pool=True, kernel=(2, 2), pool_type='avg')\n",
    "    loc = mx.symbol.Flatten(data=loc)\n",
    "    loc = mx.symbol.FullyConnected(data=loc, num_hidden=6, name=\"stn_loc\", attr=attr)\n",
    "    return loc\n",
    "\n",
    "def get_mlp():\n",
    "    \"\"\"\n",
    "    multi-layer perceptron\n",
    "    \"\"\"\n",
    "    data = mx.symbol.Variable('data')\n",
    "    fc1  = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\n",
    "    act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "    fc2  = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\n",
    "    act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "    fc3  = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "    mlp  = mx.symbol.SoftmaxOutput(data = fc3, name = 'softmax')\n",
    "    return mlp\n",
    "\n",
    "def get_lenet(add_stn=False):\n",
    "    \"\"\"\n",
    "    LeCun, Yann, Leon Bottou, Yoshua Bengio, and Patrick\n",
    "    Haffner. \"Gradient-based learning applied to document recognition.\"\n",
    "    Proceedings of the IEEE (1998)\n",
    "    \"\"\"\n",
    "    data = mx.symbol.Variable('data')\n",
    "    if(add_stn):\n",
    "        data = mx.sym.SpatialTransformer(data=data, loc=get_loc(data), target_shape = (28,28),\n",
    "                                         transform_type=\"affine\", sampler_type=\"bilinear\")\n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "    tanh2 = mx.symbol.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.symbol.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=10)\n",
    "    # loss\n",
    "    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')\n",
    "    return lenet\n",
    "\n",
    "def get_iterator(data_shape):\n",
    "    def get_iterator_impl(args, kv):\n",
    "        data_dir = args.data_dir\n",
    "        # if Windows\n",
    "        if os.name == \"nt\":\n",
    "            data_dir = data_dir[:-1] + \"\\\\\"\n",
    "        if '://' not in args.data_dir:\n",
    "            _download(data_dir)\n",
    "        flat = False if len(data_shape) == 3 else True\n",
    "\n",
    "        train           = mx.io.MNISTIter(\n",
    "            image       = data_dir + \"train-images-idx3-ubyte\",\n",
    "            label       = data_dir + \"train-labels-idx1-ubyte\",\n",
    "            input_shape = data_shape,\n",
    "            batch_size  = args.batch_size,\n",
    "            shuffle     = True,\n",
    "            flat        = flat,\n",
    "            num_parts   = kv.num_workers,\n",
    "            part_index  = kv.rank)\n",
    "\n",
    "        val = mx.io.MNISTIter(\n",
    "            image       = data_dir + \"t10k-images-idx3-ubyte\",\n",
    "            label       = data_dir + \"t10k-labels-idx1-ubyte\",\n",
    "            input_shape = data_shape,\n",
    "            batch_size  = args.batch_size,\n",
    "            flat        = flat,\n",
    "            num_parts   = kv.num_workers,\n",
    "            part_index  = kv.rank)\n",
    "\n",
    "        return (train, val)\n",
    "    return get_iterator_impl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of MXNet, there are multiple options you can use, two of which we defined earlier: mlp or lenet. In this case, we will be using mlp. Typically, this script takes a command line input and performs training based on what was entered, but we will simulate the command line entries. On the final line of the next cell, we pass in the command line variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='train an image classifer on mnist')\n",
    "    parser.add_argument('--network', type=str, default='mlp',\n",
    "                        choices = ['mlp', 'lenet', 'lenet-stn'],\n",
    "                        help = 'the cnn to use')\n",
    "    parser.add_argument('--data-dir', type=str, default='mnist/',\n",
    "                        help='the input data directory')\n",
    "    parser.add_argument('--gpus', type=str,\n",
    "                        help='the gpus will be used, e.g \"0,1,2,3\"')\n",
    "    parser.add_argument('--num-examples', type=int, default=60000,\n",
    "                        help='the number of training examples')\n",
    "    parser.add_argument('--batch-size', type=int, default=128,\n",
    "                        help='the batch size')\n",
    "    parser.add_argument('--lr', type=float, default=.1,\n",
    "                        help='the initial learning rate')\n",
    "    parser.add_argument('--model-prefix', type=str,\n",
    "                        help='the prefix of the model to load/save')\n",
    "    parser.add_argument('--save-model-prefix', type=str,\n",
    "                        help='the prefix of the model to save')\n",
    "    parser.add_argument('--num-epochs', type=int, default=10,\n",
    "                        help='the number of training epochs')\n",
    "    parser.add_argument('--load-epoch', type=int,\n",
    "                        help=\"load the model on an epoch using the model-prefix\")\n",
    "    parser.add_argument('--kv-store', type=str, default='local',\n",
    "                        help='the kvstore type')\n",
    "    parser.add_argument('--lr-factor', type=float, default=1,\n",
    "                        help='times the lr with a factor for every lr-factor-epoch epoch')\n",
    "    parser.add_argument('--lr-factor-epoch', type=float, default=1,\n",
    "                        help='the number of epoch to factor the lr, could be .5')\n",
    "    \n",
    "    return parser.parse_args('--network mlp --kv-store local'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the commands entered in previously, we can go ahead and tell MXNet to train based on our Image Classification dataset. In this lab, we are using mlp but you can easily switch up the network in the find command above to use LeNet or lenet-stn.\n",
    "\n",
    "There are a variety of other options as part of the training example. As part of the initial compilation of MXNet in lab 2, we included some extra flags, namely: \n",
    "\n",
    "`USE_KUDA = 0 \n",
    "USE_CUDNN=0\n",
    "USE_BLAS = atlas\n",
    "USE_DIST_KVSTORE = 1\n",
    "USE_S3 = 1.` \n",
    "\n",
    "USE_KUDA and USE_CUDNN disable the use of GPUs as we're using CPUs for this lab, USE_BLAS is needed for CPU processing, USE_DIST_KVSTORE will allow distributed training on multiple machines and USE_S3 will allow the use of S3 to synchronize datasets across multiple machines.\n",
    "\n",
    "As MXNet does not fully support docker distributed learning yet, we're not using it, but for a similar example, see:\n",
    "https://aws.amazon.com/blogs/compute/distributed-deep-learning-made-easy/\n",
    "\n",
    "Now we actually train. Run the next command, and when you see some output hit the stop button up top stop the training as we will be using a pre-trained model using the full imagenet dataset to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = parse_args()\n",
    "if args.network == 'mlp':\n",
    "    data_shape = (784, )\n",
    "    net = get_mlp()\n",
    "elif args.network == 'lenet-stn':\n",
    "    data_shape = (1, 28, 28)\n",
    "    net = get_lenet(True)\n",
    "else:\n",
    "    data_shape = (1, 28, 28)\n",
    "    net = get_lenet()\n",
    "train_model.fit(args, net, get_iterator(data_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should have stopped the output from above, but the output shows that learning is being done on your machine with the parameters we passed in previously. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
