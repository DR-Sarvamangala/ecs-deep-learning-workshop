{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Image Classification Model\n",
    "\n",
    "This is a demo for training a model using the a subset of the imagenet dataset. This notebook is a version of https://github.com/dmlc/mxnet/blob/master/example/image-classification/train_mnist.py where you can run the training via command line.\n",
    "\n",
    "We first load the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import find_mxnet\n",
    "import mxnet as mx\n",
    "import argparse\n",
    "import os, sys\n",
    "import train_model\n",
    "\n",
    "def _download(data_dir):\n",
    "    if not os.path.isdir(data_dir):\n",
    "        os.system(\"mkdir \" + data_dir)\n",
    "    os.chdir(data_dir)\n",
    "    if (not os.path.exists('train-images-idx3-ubyte')) or \\\n",
    "       (not os.path.exists('train-labels-idx1-ubyte')) or \\\n",
    "       (not os.path.exists('t10k-images-idx3-ubyte')) or \\\n",
    "       (not os.path.exists('t10k-labels-idx1-ubyte')):\n",
    "        import urllib, zipfile\n",
    "        zippath = os.path.join(os.getcwd(), \"mnist.zip\")\n",
    "        urllib.urlretrieve(\"http://data.mxnet.io/mxnet/data/mnist.zip\", zippath)\n",
    "        zf = zipfile.ZipFile(zippath, \"r\")\n",
    "        zf.extractall()\n",
    "        zf.close()\n",
    "        os.remove(zippath)\n",
    "    os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_loc(data, attr={'lr_mult':'0.01'}):\n",
    "    \"\"\"\n",
    "    the localisation network in lenet-stn, it will increase acc about more than 1%,\n",
    "    when num-epoch >=15\n",
    "    \"\"\"\n",
    "    loc = mx.symbol.Convolution(data=data, num_filter=30, kernel=(5, 5), stride=(2,2))\n",
    "    loc = mx.symbol.Activation(data = loc, act_type='relu')\n",
    "    loc = mx.symbol.Pooling(data=loc, kernel=(2, 2), stride=(2, 2), pool_type='max')\n",
    "    loc = mx.symbol.Convolution(data=loc, num_filter=60, kernel=(3, 3), stride=(1,1), pad=(1, 1))\n",
    "    loc = mx.symbol.Activation(data = loc, act_type='relu')\n",
    "    loc = mx.symbol.Pooling(data=loc, global_pool=True, kernel=(2, 2), pool_type='avg')\n",
    "    loc = mx.symbol.Flatten(data=loc)\n",
    "    loc = mx.symbol.FullyConnected(data=loc, num_hidden=6, name=\"stn_loc\", attr=attr)\n",
    "    return loc\n",
    "\n",
    "def get_mlp():\n",
    "    \"\"\"\n",
    "    multi-layer perceptron\n",
    "    \"\"\"\n",
    "    data = mx.symbol.Variable('data')\n",
    "    fc1  = mx.symbol.FullyConnected(data = data, name='fc1', num_hidden=128)\n",
    "    act1 = mx.symbol.Activation(data = fc1, name='relu1', act_type=\"relu\")\n",
    "    fc2  = mx.symbol.FullyConnected(data = act1, name = 'fc2', num_hidden = 64)\n",
    "    act2 = mx.symbol.Activation(data = fc2, name='relu2', act_type=\"relu\")\n",
    "    fc3  = mx.symbol.FullyConnected(data = act2, name='fc3', num_hidden=10)\n",
    "    mlp  = mx.symbol.SoftmaxOutput(data = fc3, name = 'softmax')\n",
    "    return mlp\n",
    "\n",
    "def get_lenet(add_stn=False):\n",
    "    \"\"\"\n",
    "    LeCun, Yann, Leon Bottou, Yoshua Bengio, and Patrick\n",
    "    Haffner. \"Gradient-based learning applied to document recognition.\"\n",
    "    Proceedings of the IEEE (1998)\n",
    "    \"\"\"\n",
    "    data = mx.symbol.Variable('data')\n",
    "    if(add_stn):\n",
    "        data = mx.sym.SpatialTransformer(data=data, loc=get_loc(data), target_shape = (28,28),\n",
    "                                         transform_type=\"affine\", sampler_type=\"bilinear\")\n",
    "    # first conv\n",
    "    conv1 = mx.symbol.Convolution(data=data, kernel=(5,5), num_filter=20)\n",
    "    tanh1 = mx.symbol.Activation(data=conv1, act_type=\"tanh\")\n",
    "    pool1 = mx.symbol.Pooling(data=tanh1, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # second conv\n",
    "    conv2 = mx.symbol.Convolution(data=pool1, kernel=(5,5), num_filter=50)\n",
    "    tanh2 = mx.symbol.Activation(data=conv2, act_type=\"tanh\")\n",
    "    pool2 = mx.symbol.Pooling(data=tanh2, pool_type=\"max\",\n",
    "                              kernel=(2,2), stride=(2,2))\n",
    "    # first fullc\n",
    "    flatten = mx.symbol.Flatten(data=pool2)\n",
    "    fc1 = mx.symbol.FullyConnected(data=flatten, num_hidden=500)\n",
    "    tanh3 = mx.symbol.Activation(data=fc1, act_type=\"tanh\")\n",
    "    # second fullc\n",
    "    fc2 = mx.symbol.FullyConnected(data=tanh3, num_hidden=10)\n",
    "    # loss\n",
    "    lenet = mx.symbol.SoftmaxOutput(data=fc2, name='softmax')\n",
    "    return lenet\n",
    "\n",
    "def get_iterator(data_shape):\n",
    "    def get_iterator_impl(args, kv):\n",
    "        data_dir = args.data_dir\n",
    "        # if Windows\n",
    "        if os.name == \"nt\":\n",
    "            data_dir = data_dir[:-1] + \"\\\\\"\n",
    "        if '://' not in args.data_dir:\n",
    "            _download(data_dir)\n",
    "        flat = False if len(data_shape) == 3 else True\n",
    "\n",
    "        train           = mx.io.MNISTIter(\n",
    "            image       = data_dir + \"train-images-idx3-ubyte\",\n",
    "            label       = data_dir + \"train-labels-idx1-ubyte\",\n",
    "            input_shape = data_shape,\n",
    "            batch_size  = args.batch_size,\n",
    "            shuffle     = True,\n",
    "            flat        = flat,\n",
    "            num_parts   = kv.num_workers,\n",
    "            part_index  = kv.rank)\n",
    "\n",
    "        val = mx.io.MNISTIter(\n",
    "            image       = data_dir + \"t10k-images-idx3-ubyte\",\n",
    "            label       = data_dir + \"t10k-labels-idx1-ubyte\",\n",
    "            input_shape = data_shape,\n",
    "            batch_size  = args.batch_size,\n",
    "            flat        = flat,\n",
    "            num_parts   = kv.num_workers,\n",
    "            part_index  = kv.rank)\n",
    "\n",
    "        return (train, val)\n",
    "    return get_iterator_impl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of MXNet, there are multiple options you can use, two of which we defined earlier: mlp or lenet. In this case, we will be using mlp. Typically, this script takes a command line input and performs training based on what was entered, but we will simulate the command line entries. On the final line of the next cell, we pass in the command line variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "    parser = argparse.ArgumentParser(description='train an image classifer on mnist')\n",
    "    parser.add_argument('--network', type=str, default='mlp',\n",
    "                        choices = ['mlp', 'lenet', 'lenet-stn'],\n",
    "                        help = 'the cnn to use')\n",
    "    parser.add_argument('--data-dir', type=str, default='mnist/',\n",
    "                        help='the input data directory')\n",
    "    parser.add_argument('--gpus', type=str,\n",
    "                        help='the gpus will be used, e.g \"0,1,2,3\"')\n",
    "    parser.add_argument('--num-examples', type=int, default=60000,\n",
    "                        help='the number of training examples')\n",
    "    parser.add_argument('--batch-size', type=int, default=128,\n",
    "                        help='the batch size')\n",
    "    parser.add_argument('--lr', type=float, default=.1,\n",
    "                        help='the initial learning rate')\n",
    "    parser.add_argument('--model-prefix', type=str,\n",
    "                        help='the prefix of the model to load/save')\n",
    "    parser.add_argument('--save-model-prefix', type=str,\n",
    "                        help='the prefix of the model to save')\n",
    "    parser.add_argument('--num-epochs', type=int, default=10,\n",
    "                        help='the number of training epochs')\n",
    "    parser.add_argument('--load-epoch', type=int,\n",
    "                        help=\"load the model on an epoch using the model-prefix\")\n",
    "    parser.add_argument('--kv-store', type=str, default='local',\n",
    "                        help='the kvstore type')\n",
    "    parser.add_argument('--lr-factor', type=float, default=1,\n",
    "                        help='times the lr with a factor for every lr-factor-epoch epoch')\n",
    "    parser.add_argument('--lr-factor-epoch', type=float, default=1,\n",
    "                        help='the number of epoch to factor the lr, could be .5')\n",
    "    \n",
    "    return parser.parse_args('--network mlp --kv-store local'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we actually train. Based on the commands entered in previously, we can go ahead and tell MXNet to train based on our Image Classification dataset. Hit the stop button up to stop the training as we will be using a pre-trained model to predict!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2016-11-27 12:08:16,850 Node[0] start with arguments Namespace(batch_size=128, data_dir='mnist/', gpus=None, kv_store='local', load_epoch=None, lr=0.1, lr_factor=1, lr_factor_epoch=1, model_prefix=None, network='mlp', num_epochs=10, num_examples=60000, save_model_prefix=None)\n",
      "2016-11-27 12:08:18,704 Node[0] Start training with [cpu(0)]\n",
      "2016-11-27 12:08:19,023 Node[0] Epoch[0] Batch [50]\tSpeed: 20798.33 samples/sec\tTrain-accuracy=0.703125\n",
      "2016-11-27 12:08:19,024 Node[0] Epoch[0] Batch [50]\tSpeed: 20798.33 samples/sec\tTrain-top_k_accuracy_5=0.942813\n",
      "2016-11-27 12:08:19,025 Node[0] Epoch[0] Batch [50]\tSpeed: 20798.33 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:19,026 Node[0] Epoch[0] Batch [50]\tSpeed: 20798.33 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:19,339 Node[0] Epoch[0] Batch [100]\tSpeed: 20522.16 samples/sec\tTrain-accuracy=0.903281\n",
      "2016-11-27 12:08:19,340 Node[0] Epoch[0] Batch [100]\tSpeed: 20522.16 samples/sec\tTrain-top_k_accuracy_5=0.992188\n",
      "2016-11-27 12:08:19,341 Node[0] Epoch[0] Batch [100]\tSpeed: 20522.16 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:19,343 Node[0] Epoch[0] Batch [100]\tSpeed: 20522.16 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:19,656 Node[0] Epoch[0] Batch [150]\tSpeed: 20523.75 samples/sec\tTrain-accuracy=0.910000\n",
      "2016-11-27 12:08:19,657 Node[0] Epoch[0] Batch [150]\tSpeed: 20523.75 samples/sec\tTrain-top_k_accuracy_5=0.995781\n",
      "2016-11-27 12:08:19,658 Node[0] Epoch[0] Batch [150]\tSpeed: 20523.75 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:19,660 Node[0] Epoch[0] Batch [150]\tSpeed: 20523.75 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:19,976 Node[0] Epoch[0] Batch [200]\tSpeed: 20270.42 samples/sec\tTrain-accuracy=0.926094\n",
      "2016-11-27 12:08:19,978 Node[0] Epoch[0] Batch [200]\tSpeed: 20270.42 samples/sec\tTrain-top_k_accuracy_5=0.997188\n",
      "2016-11-27 12:08:19,979 Node[0] Epoch[0] Batch [200]\tSpeed: 20270.42 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:19,980 Node[0] Epoch[0] Batch [200]\tSpeed: 20270.42 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:20,292 Node[0] Epoch[0] Batch [250]\tSpeed: 20600.17 samples/sec\tTrain-accuracy=0.939844\n",
      "2016-11-27 12:08:20,293 Node[0] Epoch[0] Batch [250]\tSpeed: 20600.17 samples/sec\tTrain-top_k_accuracy_5=0.997969\n",
      "2016-11-27 12:08:20,294 Node[0] Epoch[0] Batch [250]\tSpeed: 20600.17 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:20,296 Node[0] Epoch[0] Batch [250]\tSpeed: 20600.17 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:20,608 Node[0] Epoch[0] Batch [300]\tSpeed: 20593.34 samples/sec\tTrain-accuracy=0.942031\n",
      "2016-11-27 12:08:20,609 Node[0] Epoch[0] Batch [300]\tSpeed: 20593.34 samples/sec\tTrain-top_k_accuracy_5=0.996875\n",
      "2016-11-27 12:08:20,610 Node[0] Epoch[0] Batch [300]\tSpeed: 20593.34 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:20,611 Node[0] Epoch[0] Batch [300]\tSpeed: 20593.34 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:20,929 Node[0] Epoch[0] Batch [350]\tSpeed: 20193.35 samples/sec\tTrain-accuracy=0.943438\n",
      "2016-11-27 12:08:20,930 Node[0] Epoch[0] Batch [350]\tSpeed: 20193.35 samples/sec\tTrain-top_k_accuracy_5=0.997969\n",
      "2016-11-27 12:08:20,932 Node[0] Epoch[0] Batch [350]\tSpeed: 20193.35 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:20,933 Node[0] Epoch[0] Batch [350]\tSpeed: 20193.35 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:21,246 Node[0] Epoch[0] Batch [400]\tSpeed: 20572.89 samples/sec\tTrain-accuracy=0.944219\n",
      "2016-11-27 12:08:21,247 Node[0] Epoch[0] Batch [400]\tSpeed: 20572.89 samples/sec\tTrain-top_k_accuracy_5=0.998437\n",
      "2016-11-27 12:08:21,248 Node[0] Epoch[0] Batch [400]\tSpeed: 20572.89 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:21,249 Node[0] Epoch[0] Batch [400]\tSpeed: 20572.89 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:21,561 Node[0] Epoch[0] Batch [450]\tSpeed: 20636.10 samples/sec\tTrain-accuracy=0.952344\n",
      "2016-11-27 12:08:21,562 Node[0] Epoch[0] Batch [450]\tSpeed: 20636.10 samples/sec\tTrain-top_k_accuracy_5=0.997500\n",
      "2016-11-27 12:08:21,563 Node[0] Epoch[0] Batch [450]\tSpeed: 20636.10 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:21,564 Node[0] Epoch[0] Batch [450]\tSpeed: 20636.10 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:21,678 Node[0] Epoch[0] Resetting Data Iterator\n",
      "2016-11-27 12:08:21,680 Node[0] Epoch[0] Time cost=2.972\n",
      "2016-11-27 12:08:21,930 Node[0] Epoch[0] Validation-accuracy=0.957532\n",
      "2016-11-27 12:08:21,931 Node[0] Epoch[0] Validation-top_k_accuracy_5=0.998698\n",
      "2016-11-27 12:08:21,932 Node[0] Epoch[0] Validation-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:21,934 Node[0] Epoch[0] Validation-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:22,247 Node[0] Epoch[1] Batch [50]\tSpeed: 20982.57 samples/sec\tTrain-accuracy=0.961250\n",
      "2016-11-27 12:08:22,248 Node[0] Epoch[1] Batch [50]\tSpeed: 20982.57 samples/sec\tTrain-top_k_accuracy_5=0.998750\n",
      "2016-11-27 12:08:22,250 Node[0] Epoch[1] Batch [50]\tSpeed: 20982.57 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:22,251 Node[0] Epoch[1] Batch [50]\tSpeed: 20982.57 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:22,564 Node[0] Epoch[1] Batch [100]\tSpeed: 20556.24 samples/sec\tTrain-accuracy=0.964844\n",
      "2016-11-27 12:08:22,565 Node[0] Epoch[1] Batch [100]\tSpeed: 20556.24 samples/sec\tTrain-top_k_accuracy_5=0.998125\n",
      "2016-11-27 12:08:22,566 Node[0] Epoch[1] Batch [100]\tSpeed: 20556.24 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:22,568 Node[0] Epoch[1] Batch [100]\tSpeed: 20556.24 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:22,888 Node[0] Epoch[1] Batch [150]\tSpeed: 20046.29 samples/sec\tTrain-accuracy=0.961562\n",
      "2016-11-27 12:08:22,889 Node[0] Epoch[1] Batch [150]\tSpeed: 20046.29 samples/sec\tTrain-top_k_accuracy_5=0.998750\n",
      "2016-11-27 12:08:22,890 Node[0] Epoch[1] Batch [150]\tSpeed: 20046.29 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:22,891 Node[0] Epoch[1] Batch [150]\tSpeed: 20046.29 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:23,204 Node[0] Epoch[1] Batch [200]\tSpeed: 20543.18 samples/sec\tTrain-accuracy=0.965156\n",
      "2016-11-27 12:08:23,205 Node[0] Epoch[1] Batch [200]\tSpeed: 20543.18 samples/sec\tTrain-top_k_accuracy_5=0.999687\n",
      "2016-11-27 12:08:23,206 Node[0] Epoch[1] Batch [200]\tSpeed: 20543.18 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:23,207 Node[0] Epoch[1] Batch [200]\tSpeed: 20543.18 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:23,561 Node[0] Epoch[1] Batch [250]\tSpeed: 18166.13 samples/sec\tTrain-accuracy=0.962969\n",
      "2016-11-27 12:08:23,562 Node[0] Epoch[1] Batch [250]\tSpeed: 18166.13 samples/sec\tTrain-top_k_accuracy_5=0.999375\n",
      "2016-11-27 12:08:23,563 Node[0] Epoch[1] Batch [250]\tSpeed: 18166.13 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:23,564 Node[0] Epoch[1] Batch [250]\tSpeed: 18166.13 samples/sec\tTrain-top_k_accuracy_20=1.000000\n",
      "2016-11-27 12:08:23,883 Node[0] Epoch[1] Batch [300]\tSpeed: 20171.83 samples/sec\tTrain-accuracy=0.963906\n",
      "2016-11-27 12:08:23,884 Node[0] Epoch[1] Batch [300]\tSpeed: 20171.83 samples/sec\tTrain-top_k_accuracy_5=0.999219\n",
      "2016-11-27 12:08:23,885 Node[0] Epoch[1] Batch [300]\tSpeed: 20171.83 samples/sec\tTrain-top_k_accuracy_10=1.000000\n",
      "2016-11-27 12:08:23,886 Node[0] Epoch[1] Batch [300]\tSpeed: 20171.83 samples/sec\tTrain-top_k_accuracy_20=1.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-3cf804521525>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparse_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/root/ecs-deep-learning-workshop/mxnet/example/image-classification/train_model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(args, network, data_loader, batch_end_callback)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mkvstore\u001b[0m            \u001b[0;34m=\u001b[0m \u001b[0mkv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mbatch_end_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_end_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         epoch_end_callback = checkpoint)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, eval_data, eval_metric, epoch_end_callback, batch_end_callback, kvstore, logger, work_load_list, monitor, eval_batch_end_callback)\u001b[0m\n\u001b[1;32m    804\u001b[0m                             \u001b[0mlogger\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwork_load_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwork_load_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m                             \u001b[0meval_batch_end_callback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_batch_end_callback\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m                             sym_gen=self.sym_gen)\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/model.pyc\u001b[0m in \u001b[0;36m_train_multi_device\u001b[0;34m(symbol, ctx, arg_names, param_names, aux_names, arg_params, aux_params, begin_epoch, end_epoch, epoch_size, optimizer, kvstore, update_on_kvstore, train_data, eval_data, eval_metric, epoch_end_callback, batch_end_callback, logger, work_load_list, monitor, eval_batch_end_callback, sym_gen)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0;31m# evaluate at end, so we can lazy copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mexecutor_manager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m                 \u001b[0mnbatch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.pyc\u001b[0m in \u001b[0;36mupdate_metric\u001b[0;34m(self, metric, labels)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0;34m\"\"\"update metric with the current executor\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurr_execgrp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/executor_manager.pyc\u001b[0m in \u001b[0;36mupdate_metric\u001b[0;34m(self, metric, labels)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtexec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mislice\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_execs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m             \u001b[0mlabels_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDataParallelExecutorManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/metric.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/metric.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, labels, preds)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_label\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m             \u001b[0mpred_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mndarray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax_channel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/mxnet-0.7.0-py2.7.egg/mxnet/ndarray.pyc\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "args = parse_args()\n",
    "\n",
    "train_model.fit(args, net, get_iterator(data_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

